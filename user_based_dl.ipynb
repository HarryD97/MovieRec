{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split  # 新增\n",
    "\n",
    "# 检查GPU是否可用，并设置运行设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备：\", device)\n",
    "\n",
    "# 读取数据\n",
    "ratings_df = pd.read_csv(\"ml-32m/ratings.csv\")\n",
    "movies_df = pd.read_csv(\"ml-32m/movies.csv\")\n",
    "\n",
    "# 构造用户和电影ID到索引的映射\n",
    "unique_users = ratings_df['userId'].unique()\n",
    "unique_items = ratings_df['movieId'].unique()\n",
    "user2idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "item2idx = {item: idx for idx, item in enumerate(unique_items)}\n",
    "\n",
    "# 为了方便后续计算，将原始的 userId 和 movieId 转换为索引\n",
    "ratings_df['user_idx'] = ratings_df['userId'].map(user2idx)\n",
    "ratings_df['movie_idx'] = ratings_df['movieId'].map(item2idx)\n",
    "\n",
    "num_users = len(unique_users)\n",
    "num_items = len(unique_items)\n",
    "print(\"用户数量：\", num_users, \"电影数量：\", num_items)\n",
    "\n",
    "# -----------------------------\n",
    "# 数据划分：训练集 80%，验证集 10%，测试集 10%\n",
    "# -----------------------------\n",
    "train_val_df, test_df = train_test_split(ratings_df, test_size=0.1, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.1111, random_state=42)  # 0.1111≈10%/90%\n",
    "\n",
    "print(\"训练集大小：\", len(train_df))\n",
    "print(\"验证集大小：\", len(val_df))\n",
    "print(\"测试集大小：\", len(test_df))\n",
    "\n",
    "# -----------------------------\n",
    "# 自定义 Dataset\n",
    "# -----------------------------\n",
    "class MovieRatingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        user = torch.tensor(row['user_idx'], dtype=torch.long)\n",
    "        item = torch.tensor(row['movie_idx'], dtype=torch.long)\n",
    "        rating = torch.tensor(row['rating'], dtype=torch.float)\n",
    "        return user, item, rating\n",
    "\n",
    "train_dataset = MovieRatingDataset(train_df)\n",
    "val_dataset = MovieRatingDataset(val_df)\n",
    "test_dataset = MovieRatingDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 定义神经协同过滤模型（NCF）\n",
    "# -----------------------------\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        x = torch.cat([user_emb, item_emb], dim=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        rating = torch.sigmoid(x) * 5.0\n",
    "        return rating.squeeze()\n",
    "\n",
    "model = NCF(num_users, num_items, embedding_dim=32).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 模型训练\n",
    "# -----------------------------\n",
    "num_epochs = 1  \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100)\n",
    "    for step, (user, item, rating) in enumerate(progress_bar):\n",
    "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user, item)\n",
    "        loss = criterion(output, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * user.size(0)\n",
    "        progress_bar.set_postfix({'step': step, 'loss': loss.item()})\n",
    "    epoch_loss /= len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 定义推荐函数（与原代码基本保持一致）\n",
    "# -----------------------------\n",
    "def recommend_movies(model, user_id, ratings_df, movies_df, user2idx, item2idx, top_n=5):\n",
    "    model.eval()\n",
    "    user_idx = user2idx[user_id]\n",
    "    rated_items = ratings_df[ratings_df[\"userId\"] == user_id][\"movie_idx\"].tolist()\n",
    "    all_item_indices = np.arange(num_items)\n",
    "    candidate_indices = [i for i in all_item_indices if i not in rated_items]\n",
    "    if len(candidate_indices) == 0:\n",
    "        print(\"用户已经对所有电影评分，无可推荐项目。\")\n",
    "        return None\n",
    "    user_tensor = torch.tensor([user_idx] * len(candidate_indices), dtype=torch.long).to(device)\n",
    "    item_tensor = torch.tensor(candidate_indices, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(user_tensor, item_tensor)\n",
    "    preds = preds.cpu().numpy()\n",
    "    top_indices = np.argsort(preds)[::-1][:top_n]\n",
    "    recommended_item_indices = [candidate_indices[i] for i in top_indices]\n",
    "    idx2item = {idx: movie for movie, idx in item2idx.items()}\n",
    "    recommended_movie_ids = [idx2item[i] for i in recommended_item_indices]\n",
    "    recommendations = movies_df[movies_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "    return recommendations\n",
    "\n",
    "# -----------------------------\n",
    "# 测试推荐功能\n",
    "# -----------------------------\n",
    "user_id_to_recommend = unique_users[0]\n",
    "recs = recommend_movies(model, user_id_to_recommend, ratings_df, movies_df, user2idx, item2idx, top_n=5)\n",
    "if recs is not None:\n",
    "    print(f\"\\n对用户 {user_id_to_recommend} 的电影推荐：\")\n",
    "    print(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/ncf_model.pth\"\n",
    "def save_model(model, optimizer, epoch, filepath=model_path):\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"模型已保存到 {filepath}\")\n",
    "save_model(model, optimizer, num_epochs, filepath=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "      mse: 均方误差\n",
    "      rmse: 根均方误差\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user, item, rating in dataloader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            output = model(user, item)\n",
    "            loss = criterion(output, rating)\n",
    "            batch_size = user.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "    mse = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "    rmse = math.sqrt(mse)\n",
    "    print(f\"Evaluation Metrics: MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "    return mse, rmse\n",
    "\n",
    "# 示例：使用 test_loader 评估模型\n",
    "mse, rmse = evaluate_model(model, test_loader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Answer-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
